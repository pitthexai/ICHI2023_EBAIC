{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pitthexai/ICHI2023_EBAIC/blob/main/Code/1_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "EWexO9qnlAfU"
      },
      "id": "EWexO9qnlAfU"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jPsV6JvMf7_C"
      },
      "id": "jPsV6JvMf7_C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "57eed16d",
      "metadata": {
        "id": "57eed16d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BONY_ANATOMY = \"knee\""
      ],
      "metadata": {
        "id": "yobiMwGTiUiJ"
      },
      "id": "yobiMwGTiUiJ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "08b1a3cb",
      "metadata": {
        "id": "08b1a3cb"
      },
      "outputs": [],
      "source": [
        "# Directories for\n",
        "if BONY_ANATOMY == \"knee\":\n",
        "    filename = \"knee_seg_sample.csv\"\n",
        "    directory = \"KneeSample\"\n",
        "    zipfile = \"knee_sample.zip\"\n",
        "else:\n",
        "    filename = \"hip_seg_sample.csv\"\n",
        "    directory = \"HipSample\"\n",
        "    zipfile = \"hip_sample.zip\"\n",
        "\n",
        "zipfile_loc = f\"/content/drive/MyDrive/GoogleColabProjects/EBAIC_2023/EBAIC2023_HipKnee_Datasets/{zipfile}\"\n",
        "data_location = f\"/content/data/{directory}/{filename}\"\n",
        "data_save_location = f\"/content/drive/MyDrive/GoogleColabProjects/EBAIC_2023/EBAIC2023_HipKnee_Datasets/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(data_save_location):\n",
        "    with ZipFile(zipfile_loc, 'r') as zipf:\n",
        "        zipf.extractall(\"/content/\")"
      ],
      "metadata": {
        "id": "TA5oau2Vg1XF"
      },
      "id": "TA5oau2Vg1XF",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "885fbd86",
      "metadata": {
        "id": "885fbd86"
      },
      "outputs": [],
      "source": [
        "def generate_train_test_split(csv_pth, filter_query=None):\n",
        "    data_records = pd.read_csv(csv_pth)\n",
        "    data_records = data_records[data_records.id != 9025994].reset_index(drop=True)\n",
        "    if filter_query:\n",
        "        data_records = data_records.query(filter_query)\n",
        "\n",
        "    train, test = train_test_split(data_records.id.unique(), test_size=0.3, random_state=42)\n",
        "    valid, test = train_test_split(test, test_size=0.5, random_state=42)\n",
        "\n",
        "    train = data_records[data_records.id.isin(train)].reset_index(drop=True)\n",
        "    valid = data_records[data_records.id.isin(valid)].reset_index(drop=True)\n",
        "    test = data_records[data_records.id.isin(test)].reset_index(drop=True)\n",
        "\n",
        "    return train, valid, test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_dataset(data, by_filter1, by_filter2):\n",
        "    filtered1 = data.query(by_filter1)\n",
        "    filtered2 = data.query(by_filter2)\n",
        "\n",
        "    min_sample_size = np.minimum(len(filtered1), len(filtered2))\n",
        "    samp1 = filtered1.sample(min_sample_size,  random_state = 42)\n",
        "    samp2 = filtered2.sample(min_sample_size,  random_state = 42)\n",
        "\n",
        "    balanced_data = pd.concat([samp1, samp2])\n",
        "\n",
        "    print(f\"Training dataset reduced from size of {len(data)} samples to a balanced dataset of size {len(balanced_data)} samples\")\n",
        "\n",
        "    return balanced_data"
      ],
      "metadata": {
        "id": "aMLg3-Zki8DG"
      },
      "id": "aMLg3-Zki8DG",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "816319f1",
      "metadata": {
        "id": "816319f1"
      },
      "outputs": [],
      "source": [
        "## Baseline Datasets\n",
        "train_all, valid_all, test_all = generate_train_test_split(data_location)\n",
        "train_white, valid_white, test_white = generate_train_test_split(data_location, filter_query=\"P02RACE == '1: White or Caucasian'\")\n",
        "train_black, valid_black, test_black = generate_train_test_split(data_location, filter_query=\"P02RACE == '2: Black or African American'\")\n",
        "train_male, valid_male, test_male = generate_train_test_split(data_location, filter_query=\"P02SEX == '1: Male'\")\n",
        "train_female, valid_female, test_female = generate_train_test_split(data_location, filter_query=\"P02SEX == '2: Female'\")\n",
        "\n",
        "balanced_gender_train = balance_dataset(train_all, \"P02SEX == '1: Male'\", \"P02SEX == '2: Female'\")\n",
        "balanced_race_train = balance_dataset(train_all, \"P02RACE == '1: White or Caucasian'\", \"P02RACE == '2: Black or African American'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Datasets\n",
        "if BONY_ANATOMY == \"knee\":\n",
        "    train_all.to_csv(os.path.join(data_save_location, \"knee_train_all.csv\"), index=False)\n",
        "    valid_all.to_csv(os.path.join(data_save_location, \"knee_valid_all.csv\"), index=False)\n",
        "    test_all.to_csv(os.path.join(data_save_location, \"knee_test_all.csv\"), index=False)\n",
        "\n",
        "    train_white.to_csv(os.path.join(data_save_location, \"knee_train_race-white.csv\"), index=False)\n",
        "    valid_white.to_csv(os.path.join(data_save_location, \"knee_valid_race-white.csv\"), index=False)\n",
        "    test_white.to_csv(os.path.join(data_save_location, \"knee_test_race-white.csv\"), index=False)\n",
        "\n",
        "    train_black.to_csv(os.path.join(data_save_location, \"knee_train_race-black.csv\"), index=False)\n",
        "    valid_black.to_csv(os.path.join(data_save_location, \"knee_valid_race-black.csv\"), index=False)\n",
        "    test_black.to_csv(os.path.join(data_save_location, \"knee_test_race-black.csv\"), index=False)\n",
        "\n",
        "    train_male.to_csv(os.path.join(data_save_location, \"knee_train_gender-male.csv\"), index=False)\n",
        "    valid_male.to_csv(os.path.join(data_save_location, \"knee_valid_gender-male.csv\"), index=False)\n",
        "    test_male.to_csv(os.path.join(data_save_location, \"knee_test_gender-male.csv\"), index=False)\n",
        "\n",
        "    train_female.to_csv(os.path.join(data_save_location, \"knee_train_gender-female.csv\"), index=False)\n",
        "    valid_female.to_csv(os.path.join(data_save_location, \"knee_valid_gender-female.csv\"), index=False)\n",
        "    test_female.to_csv(os.path.join(data_save_location, \"knee_test_gender-female.csv\"), index=False)\n",
        "\n",
        "    balanced_gender_train.to_csv(os.path.join(data_save_location, \"knee_train_balanced_gender.csv\"), index=False)\n",
        "    balanced_race_train.to_csv(os.path.join(data_save_location, \"knee_train_balanced_race.csv\"), index=False)\n",
        "else:\n",
        "    train_all.to_csv(os.path.join(data_save_location, \"hip_train_all.csv\"), index=False)\n",
        "    valid_all.to_csv(os.path.join(data_save_location, \"hip_valid_all.csv\"), index=False)\n",
        "    test_all.to_csv(os.path.join(data_save_location, \"hip_test_all.csv\"), index=False)\n",
        "\n",
        "    train_white.to_csv(os.path.join(data_save_location, \"hip_train_race-white.csv\"), index=False)\n",
        "    valid_white.to_csv(os.path.join(data_save_location, \"hip_valid_race-white.csv\"), index=False)\n",
        "    test_white.to_csv(os.path.join(data_save_location, \"hip_test_race-white.csv\"), index=False)\n",
        "\n",
        "    train_black.to_csv(os.path.join(data_save_location, \"hip_train_race-black.csv\"), index=False)\n",
        "    valid_black.to_csv(os.path.join(data_save_location, \"hip_valid_race-black.csv\"), index=False)\n",
        "    test_black.to_csv(os.path.join(data_save_location, \"hip_test_race-black.csv\"), index=False)\n",
        "\n",
        "    train_male.to_csv(os.path.join(data_save_location, \"hip_train_gender-male.csv\"), index=False)\n",
        "    valid_male.to_csv(os.path.join(data_save_location, \"hip_valid_gender-male.csv\"), index=False)\n",
        "    test_male.to_csv(os.path.join(data_save_location, \"hip_test_gender-male.csv\"), index=False)\n",
        "\n",
        "    train_female.to_csv(os.path.join(data_save_location, \"hip_train_gender-female.csv\"), index=False)\n",
        "    valid_female.to_csv(os.path.join(data_save_location, \"hip_valid_gender-female.csv\"), index=False)\n",
        "    test_female.to_csv(os.path.join(data_save_location, \"hip_test_gender-female.csv\"), index=False)\n",
        "\n",
        "    balanced_gender_train.to_csv(os.path.join(data_save_location, \"hip_train_balanced_gender.csv\"), index=False)\n",
        "    balanced_race_train.to_csv(os.path.join(data_save_location, \"hip_train_balanced_race.csv\"), index=False)"
      ],
      "metadata": {
        "id": "El9YVZ_ch5JD"
      },
      "id": "El9YVZ_ch5JD",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1RBp7G8wm2LW"
      },
      "id": "1RBp7G8wm2LW",
      "execution_count": 9,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:pytorch113_p310_gpu_v1]",
      "language": "python",
      "name": "conda-env-pytorch113_p310_gpu_v1-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}